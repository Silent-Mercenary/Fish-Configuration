#A.I. utils
    #Ollama Alias'es
    alias model-list='ollama list' # pulls the list of models installed
    alias pull-llm='ollama pull' # pulls an ai model, only from ollama.

# models gotten from ollama - all models will run from CPU  and GPU mix, 7B models max on GPU and 12B max on CPU

    alias qwen3='ollama run qwen3:8b'
